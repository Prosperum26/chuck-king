/**
 * AIMessageGenerator - Generates AI taunt messages + NPC dialog (intro, stage, ending)
 * Tr√™u ch·ªçc: death/idle/stuck (API ho·∫∑c default)
 * Dialog: intro, stage1-4, ending (API ho·∫∑c default, output chia th√†nh nhi·ªÅu d√≤ng)
 */
import {
    DEFAULT_TAUNT_MESSAGES,
    TAUNT_NPC_NAME,
    TAUNT_PROMPT_BASE,
    TAUNT_TRIGGER_DESCRIPTIONS,
    DEFAULT_DIALOGS,
    DIALOG_PROMPTS,
} from '../config/NPCDialogConfig.js';

/** Dialog type keys */
export const DIALOG_TYPES = ['intro', 'stage1', 'stage2', 'stage3', 'stage4', 'ending'];

export class AIMessageGenerator {
    constructor() {
        this.hardcodedMessages = DEFAULT_TAUNT_MESSAGES;
        this.defaultDialogs = DEFAULT_DIALOGS;

        this.currentMessage = null;
        this.apiEndpoint = null;
        this.apiKey = null;
        this.model = 'gpt-3.5-turbo';
        this.callInProgress = false;
        this.dialogCallInProgress = false;
    }
    
    /**
     * Generate AI message based on trigger type and context
     * @param {string} triggerType - 'death', 'idle', or 'stuck'
     * @param {object} context - Event tracker context
     */
    async generateMessage(triggerType, context) {
        try {
            // Try to call AI API first (n·∫øu c√≥ API config)
            if (this.apiEndpoint && this.apiKey) {
                const message = await this.callAIAPI(triggerType, context);
                if (message) {
                    this.currentMessage = message;
                    this.dispatchMessage(message);
                    return;
                }
            }
        } catch (error) {
            console.warn('[AIMessageGenerator] AI API call failed, using hardcoded:', error.message);
        }
        
        // Fallback to hardcoded messages n·∫øu kh√¥ng c√≥ API ho·∫∑c API fail
        const messages = this.hardcodedMessages[triggerType] || this.hardcodedMessages.death;
        const randomMessage = messages[Math.floor(Math.random() * messages.length)];
        this.currentMessage = randomMessage;
        console.log(`[AIMessageGenerator] üí¨ ${triggerType}: "${randomMessage}"`);
        this.dispatchMessage(randomMessage);
    }
    
    /**
     * Call AI API to generate message using AICallLogic
     * @param {string} triggerType 
     * @param {object} context 
     * @returns {Promise<string|null>}
     */
    async callAIAPI(triggerType, context) {
        if (!this.apiEndpoint || !this.apiKey) {
            return null;
        }

        if (this.callInProgress) {
            console.warn('[AIMessageGenerator] AI call already in progress, skipping...');
            return null;
        }

        this.callInProgress = true;

        try {
            const prompt = this.buildPrompt(triggerType, context);
            
            // T·∫°o timeout controller
            const controller = new AbortController();
            const timeoutId = setTimeout(() => {
                controller.abort();
                console.error('[AIMessageGenerator] ‚è±Ô∏è API Timeout (15s)');
            }, 15000);

            const response = await fetch(this.apiEndpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.apiKey}`
                },
                body: JSON.stringify({
                    model: this.model,
                    messages: [
                        {
                            role: 'user',
                            content: prompt
                        }
                    ],
                    max_tokens: 40,
                    temperature: 0.9
                }),
                signal: controller.signal
            });

            clearTimeout(timeoutId);

            if (!response.ok) {
                // Log error nh∆∞ng kh√¥ng throw - fallback v·ªÅ hardcoded
                const errorStatus = response.status;
                let errorMsg = '';
                
                if (errorStatus === 401) {
                    errorMsg = '‚ùå API Key sai ho·∫∑c h·∫øt h·∫°n (401)';
                } else if (errorStatus === 403) {
                    errorMsg = '‚ùå Kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng API (403)';
                } else if (errorStatus === 429) {
                    errorMsg = '‚ö†Ô∏è H·∫øt quota/rate limit (429) - Th·ª≠ l·∫°i sau';
                } else if (errorStatus >= 500) {
                    errorMsg = `‚ùå Server error (${errorStatus})`;
                } else {
                    errorMsg = `‚ùå API error ${errorStatus}`;
                }
                
                console.error(`[AIMessageGenerator] ${errorMsg}`);
                return null;
            }

            const data = await response.json();

            // Parse OpenAI response
            const message = data.choices?.[0]?.message?.content || null;

            if (message && message.split(' ').length <= 20) {
                console.log(`[AIMessageGenerator] ü§ñ AI: "${message}"`);
                return message.trim();
            }

            return null;
        } catch (error) {
            // Handle timeout, network errors, etc
            if (error.name === 'AbortError') {
                console.error('[AIMessageGenerator] ‚è±Ô∏è API Timeout');
            } else if (error instanceof TypeError) {
                console.error('[AIMessageGenerator] ‚ùå Network/URL error:', error.message);
            } else {
                console.error('[AIMessageGenerator] ‚ùå Error:', error.message);
            }
            return null;
        } finally {
            this.callInProgress = false;
        }
    }
    
    /**
     * Build prompt for AI based on trigger type (d√πng config: TAUNT_PROMPT_BASE + TAUNT_TRIGGER_DESCRIPTIONS)
     */
    buildPrompt(triggerType, context) {
        const deathCountInZone = context.deathZones?.[context.lastDeathZone] || 0;
        const vars = {
            deathCount: context.deathCount,
            idleTime: Math.floor(context.idleTime),
            deathsInZone: deathCountInZone,
            lastDeathZone: context.lastDeathZone || 'bottom',
        };
        let triggerDesc = TAUNT_TRIGGER_DESCRIPTIONS[triggerType] || TAUNT_TRIGGER_DESCRIPTIONS.death;
        for (const [key, value] of Object.entries(vars)) {
            triggerDesc = triggerDesc.replace(new RegExp(`{{${key}}}`, 'g'), String(value));
        }
        return TAUNT_PROMPT_BASE.replace('{{triggerDesc}}', triggerDesc);
    }
    
    /**
     * Dispatch taunt message ‚Üí NPC dialog box (event 'npcTaunt' ƒë·ªÉ NPCDialogSystem hi·ªÉn th·ªã)
     */
    dispatchMessage(message) {
        const event = new CustomEvent('npcTaunt', {
            detail: { message, npcName: TAUNT_NPC_NAME }
        });
        window.dispatchEvent(event);
    }

    /**
     * L·∫•y n·ªôi dung dialog (intro / stage1-4 / ending). C√≥ API th√¨ g·ªçi API v√† chia d√≤ng, kh√¥ng th√¨ d√πng default.
     * @param {string} dialogType - 'intro' | 'stage1' | 'stage2' | 'stage3' | 'stage4' | 'ending'
     * @returns {Promise<{npcName: string, dialogs: string[]}>}
     */
    async getDialogContent(dialogType) {
        const defaultData = this.defaultDialogs[dialogType];
        if (!defaultData) {
            return { npcName: 'NPC', dialogs: ['...'] };
        }

        if (this.apiEndpoint && this.apiKey && !this.dialogCallInProgress) {
            try {
                const result = await this.callDialogAPI(dialogType);
                if (result && result.dialogs && result.dialogs.length > 0) {
                    return result;
                }
            } catch (e) {
                console.warn('[AIMessageGenerator] Dialog API failed, using default:', e.message);
            }
        }

        return {
            npcName: defaultData.npcName,
            dialogs: [...defaultData.dialogs]
        };
    }

    /**
     * G·ªçi API l·∫•y dialog theo type, parse response th√†nh nhi·ªÅu d√≤ng (chia b·∫±ng \n ho·∫∑c . )
     */
    async callDialogAPI(dialogType) {
        if (!this.apiEndpoint || !this.apiKey) return null;
        if (this.dialogCallInProgress) return null;

        this.dialogCallInProgress = true;
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 15000);

        try {
            const prompt = this.buildDialogPrompt(dialogType);
            const response = await fetch(this.apiEndpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.apiKey}`
                },
                body: JSON.stringify({
                    model: this.model,
                    messages: [{ role: 'user', content: prompt }],
                    max_tokens: 300,
                    temperature: 0.8
                }),
                signal: controller.signal
            });
            clearTimeout(timeoutId);

            if (!response.ok) return null;
            const data = await response.json();
            const raw = (data.choices?.[0]?.message?.content || '').trim();
            if (!raw) return null;

            // Chia output: ∆∞u ti√™n xu·ªëng d√≤ng, kh√¥ng th√¨ chia theo c√¢u (d·∫•u ch·∫•m + space)
            let lines = raw.split(/\n+/).map(s => s.trim()).filter(Boolean);
            if (lines.length <= 1) {
                lines = raw.split(/\.\s+/).map(s => (s.trim() + (s.trim().endsWith('.') ? '' : '.')).trim()).filter(Boolean);
            }
            if (lines.length === 0) lines = [raw];

            const defaultData = this.defaultDialogs[dialogType] || { npcName: 'üëæ NPC' };
            return {
                npcName: defaultData.npcName,
                dialogs: lines
            };
        } catch (err) {
            if (err.name === 'AbortError') console.error('[AIMessageGenerator] Dialog API timeout');
            return null;
        } finally {
            this.dialogCallInProgress = false;
        }
    }

    /**
     * T·∫°o prompt cho t·ª´ng lo·∫°i dialog (intro, stage1-4, ending) t·ª´ config DIALOG_PROMPTS
     */
    buildDialogPrompt(dialogType) {
        return DIALOG_PROMPTS[dialogType] || DIALOG_PROMPTS.intro;
    }
    
    /**
     * Configure AI API endpoint
     */
    setAPIEndpoint(endpoint, apiKey = null, model = 'gpt-3.5-turbo') {
        this.apiEndpoint = endpoint;
        this.apiKey = apiKey;
        this.model = model;
    }
}

