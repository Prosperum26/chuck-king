/**
 * AIMessageGenerator - Generates AI taunt messages
 * S·ª≠ d·ª•ng AICallLogic ƒë·ªÉ g·ªçi API API (n·∫øu c√≥)
 */
import { AICallLogic } from './AICallLogic.js';

export class AIMessageGenerator {
    constructor() {
        // Hardcoded taunt messages
        this.hardcodedMessages = {
            death: [
                "L·∫°i ch·∫øt r·ªìi √†?",
                "Gi·ªèi qu√° nh·ªâ!",
                "L·∫ßn th·ª© m·∫•y r·ªìi?",
                "C·ªë g·∫Øng l√™n n√†o!",
                "D·ªÖ v·∫≠y m√† kh√¥ng l√†m ƒë∆∞·ª£c?",
                "Th·∫≠t l√† t·ªá...",
                "L·∫°i r∆°i xu·ªëng √†?",
                "Ch√°n qu√° ƒëi!",
            ],
            idle: [
                "ƒêang l√†m g√¨ ƒë·∫•y?",
                "Ng·ªß r·ªìi √†?",
                "Ch∆°i hay kh√¥ng ch∆°i?",
                "B·ªè cu·ªôc r·ªìi √†?",
                "C√≤n s·ªëng kh√¥ng?",
                "ƒê·ªông ƒë·∫≠y ƒëi ch·ª©!",
            ],
            stuck: [
                "K·∫πt ·ªü ƒë√¢y r·ªìi √†?",
                "L·∫°i ch·∫øt ·ªü ch·ªó n√†y n·ªØa?",
                "H·ªçc h·ªèi ƒëi ch·ª©!",
                "L√†m sao m√† ch·∫øt ho√†i v·∫≠y?",
                "Th·ª≠ c√°ch kh√°c ƒëi!",
                "Ngu qu√°!",
            ]
        };
        
        this.currentMessage = null;
        this.apiEndpoint = null;
        this.apiKey = null;
        this.model = 'gpt-3.5-turbo';
        this.callInProgress = false;
    }
    
    /**
     * Generate AI message based on trigger type and context
     * @param {string} triggerType - 'death', 'idle', or 'stuck'
     * @param {object} context - Event tracker context
     */
    async generateMessage(triggerType, context) {
        try {
            // Try to call AI API first (n·∫øu c√≥ API config)
            if (this.apiEndpoint && this.apiKey) {
                const message = await this.callAIAPI(triggerType, context);
                if (message) {
                    this.currentMessage = message;
                    this.dispatchMessage(message);
                    return;
                }
            }
        } catch (error) {
            console.warn('[AIMessageGenerator] AI API call failed, using hardcoded:', error.message);
        }
        
        // Fallback to hardcoded messages n·∫øu kh√¥ng c√≥ API ho·∫∑c API fail
        const messages = this.hardcodedMessages[triggerType] || this.hardcodedMessages.death;
        const randomMessage = messages[Math.floor(Math.random() * messages.length)];
        this.currentMessage = randomMessage;
        console.log(`[AIMessageGenerator] üí¨ ${triggerType}: "${randomMessage}"`);
        this.dispatchMessage(randomMessage);
    }
    
    /**
     * Call AI API to generate message using AICallLogic
     * @param {string} triggerType 
     * @param {object} context 
     * @returns {Promise<string|null>}
     */
    async callAIAPI(triggerType, context) {
        if (!this.apiEndpoint || !this.apiKey) {
            return null;
        }

        if (this.callInProgress) {
            console.warn('[AIMessageGenerator] AI call already in progress, skipping...');
            return null;
        }

        this.callInProgress = true;

        try {
            const prompt = this.buildPrompt(triggerType, context);
            
            // T·∫°o timeout controller
            const controller = new AbortController();
            const timeoutId = setTimeout(() => {
                controller.abort();
                console.error('[AIMessageGenerator] ‚è±Ô∏è API Timeout (15s)');
            }, 15000);

            const response = await fetch(this.apiEndpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.apiKey}`
                },
                body: JSON.stringify({
                    model: this.model,
                    messages: [
                        {
                            role: 'user',
                            content: prompt
                        }
                    ],
                    max_tokens: 40,
                    temperature: 0.9
                }),
                signal: controller.signal
            });

            clearTimeout(timeoutId);

            if (!response.ok) {
                // Log error nh∆∞ng kh√¥ng throw - fallback v·ªÅ hardcoded
                const errorStatus = response.status;
                let errorMsg = '';
                
                if (errorStatus === 401) {
                    errorMsg = '‚ùå API Key sai ho·∫∑c h·∫øt h·∫°n (401)';
                } else if (errorStatus === 403) {
                    errorMsg = '‚ùå Kh√¥ng c√≥ quy·ªÅn s·ª≠ d·ª•ng API (403)';
                } else if (errorStatus === 429) {
                    errorMsg = '‚ö†Ô∏è H·∫øt quota/rate limit (429) - Th·ª≠ l·∫°i sau';
                } else if (errorStatus >= 500) {
                    errorMsg = `‚ùå Server error (${errorStatus})`;
                } else {
                    errorMsg = `‚ùå API error ${errorStatus}`;
                }
                
                console.error(`[AIMessageGenerator] ${errorMsg}`);
                return null;
            }

            const data = await response.json();

            // Parse OpenAI response
            const message = data.choices?.[0]?.message?.content || null;

            if (message && message.split(' ').length <= 20) {
                console.log(`[AIMessageGenerator] ü§ñ AI: "${message}"`);
                return message.trim();
            }

            return null;
        } catch (error) {
            // Handle timeout, network errors, etc
            if (error.name === 'AbortError') {
                console.error('[AIMessageGenerator] ‚è±Ô∏è API Timeout');
            } else if (error instanceof TypeError) {
                console.error('[AIMessageGenerator] ‚ùå Network/URL error:', error.message);
            } else {
                console.error('[AIMessageGenerator] ‚ùå Error:', error.message);
            }
            return null;
        } finally {
            this.callInProgress = false;
        }
    }
    
    /**
     * Build prompt for AI based on trigger type
     */
    buildPrompt(triggerType, context) {
        const deathCountInZone = context.deathZones[context.lastDeathZone] || 0;
        
        const triggerDesc = {
            death: `Ng∆∞·ªùi ch∆°i v·ª´a ch·∫øt l·∫ßn th·ª© ${context.deathCount}.`,
            idle: `Ng∆∞·ªùi ch∆°i ƒë√£ kh√¥ng l√†m g√¨ trong ${Math.floor(context.idleTime)} gi√¢y.`,
            stuck: `Ng∆∞·ªùi ch∆°i ƒë√£ ch·∫øt ${deathCountInZone} l·∫ßn ·ªü khu v·ª±c "${context.lastDeathZone}" v√† v·∫´n kh√¥ng th·ªÉ v∆∞·ª£t qua.`
        };
        
        const basePrompt = `B·∫°n l√† m·ªôt NPC m·ªâa mai v√¥ c√πng cay ƒë·∫Øng v√† t·ªá b·∫°o trong game platformer. ${triggerDesc[triggerType]} H√£y n√≥i m·ªôt c√¢u ng·∫Øn (t·ªëi ƒëa 15-20 t·ª´) ƒë·ªÉ tr√™u ch·ªçc v√† ch√¢m bi·∫øm ng∆∞·ªùi ch∆°i m·ªôt c√°ch c∆° c·∫•u, ƒëanh th√©p v√† v√¥ duy√™n. Kh√¥ng gi·∫£i th√≠ch, ch·ªâ tr·∫£ v·ªÅ c√¢u n√≥i ng·∫Øn g·ªçn.`;
        
        return basePrompt;
    }
    
    /**
     * Dispatch message event to UI
     */
    dispatchMessage(message) {
        const event = new CustomEvent('aiMessage', {
            detail: { message }
        });
        window.dispatchEvent(event);
    }
    
    /**
     * Configure AI API endpoint
     */
    setAPIEndpoint(endpoint, apiKey = null, model = 'gpt-3.5-turbo') {
        this.apiEndpoint = endpoint;
        this.apiKey = apiKey;
        this.model = model;
    }
}

